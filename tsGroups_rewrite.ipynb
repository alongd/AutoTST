{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path\n",
    "import time\n",
    "import math\n",
    "import numpy\n",
    "import pylab\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "matplotlib.rc('mathtext', fontset='stixsans', default='regular')\n",
    "import re\n",
    "import rmgpy\n",
    "from rmgpy.quantity import constants\n",
    "from rmgpy.kinetics import Arrhenius, ArrheniusEP, KineticsData\n",
    "from rmgpy.data.base import getAllCombinations\n",
    "from rmgpy.data.kinetics.transitionstates import *\n",
    "from autotst.database import *\n",
    "from rmgpy.species import Species\n",
    "from rmgpy.data.rmg import RMGDatabase\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TS_Database_Update(families, auto_save = False):\n",
    "    \"\"\"\n",
    "    Loads RMG Databse,\n",
    "    Creaes instance of TS_updater for each reaction family in families,\n",
    "    Return dictionary of family:family's instance of the updater\n",
    "    \"\"\"\n",
    "    \n",
    "    assert isinstance(families, list), \"Families must be a list. If singular family, still keep it in list\"\n",
    "    acceptable_families = os.listdir(os.path.join(os.path.expandvars(\"$RMGpy\"), \"..\", \"AutoTST\", \"database\"))\n",
    "    for family in families:\n",
    "        assert isinstance(family, str), \"Family names must be provided as strings\"\n",
    "        if family.upper() not in (family.upper() for family in acceptable_families):\n",
    "            logging.warning('\"{}\" is not a known Kinetics Family'.format(family))\n",
    "            families.remove(family)\n",
    "    \n",
    "    logging.info(\"Loading RMG Database...\")\n",
    "    rmg_database = RMGDatabase()\n",
    "    database_path = os.path.join(os.path.expandvars('$RMGpy'), \"..\",  'RMG-database', 'input')\n",
    "    \n",
    "    try:\n",
    "        rmg_database.load(database_path,\n",
    "                         #kineticsFamilies=['H_Abstraction'],\n",
    "                         kineticsFamilies=families,\n",
    "                         transportLibraries=[],\n",
    "                         reactionLibraries=[],\n",
    "                         seedMechanisms=[],\n",
    "                         thermoLibraries=['primaryThermoLibrary', 'thermo_DFT_CCSDTF12_BAC', 'CBS_QB3_1dHR' ],\n",
    "                         solvation=False,\n",
    "                         )\n",
    "    except:\n",
    "        logging.error(\"Failed to Load RMG Database at {}\".format(database_path))\n",
    "        return\n",
    "    \n",
    "    Databases = {family:TS_Updater(family, rmg_database) for family in families}\n",
    "    \n",
    "    if auto_save == True:\n",
    "        save_all_individual_databases(Databases)\n",
    "    \n",
    "    return Databases\n",
    "\n",
    "def save_all_individual_databases(Databases):\n",
    "    \"\"\"\n",
    "    To save all TS_updater instances by means of the dict supplied by TS_Database_Update()\n",
    "    \"\"\"\n",
    "    for family, database in Databases:\n",
    "        database.save_database()\n",
    "    return\n",
    "    \n",
    "################################################################################################\n",
    "\n",
    "class TS_Updater:\n",
    "    \"\"\"\n",
    "    Class for use in updating TS training databases\n",
    "    \n",
    "    Attributes:\n",
    "    self.family                 : Relavent Reaction Family\n",
    "    self.path                   : Path to family\n",
    "    self.database               : Source for TS geometries\n",
    "    self.training_set           : Lists of Reaction and corresponding TS Geometries\n",
    "    \n",
    "    self.top_nodes              : The two top nodes of the tree of related structures\n",
    "    self.all_entries            : All the nodes in the tree\n",
    "    \n",
    "    self.direct_groups          : Group that is directly matched with reactant structure\n",
    "    self.nodes_to_update        : Unique list of direct groups and their ancestors\n",
    "    self.group_ancestors        : Dict organized by {direct group: list of direct groups and its ancestors}\n",
    "    self.reaction_templates     : The two groups associated with a given reaction's reactants, organized by reaction\n",
    "    \n",
    "    self.groupComments          : Templates that are relavent to that entry\n",
    "    self.groupCounts            : Number of relavant combinations of groups that contribute to that entry\n",
    "    self.groupUncertainties     : Uncertainty in the optimized TS geometry for that node/entry\n",
    "    self.groupValues            : Optimized TS geometry for that node/entry\n",
    "\n",
    "    self.A                      : Binary Matrix (all combinations of those relavent groups for all reactions) by (relavant groups + 1)\n",
    "    self.b                      : Ax=b, x is found, b is (all combinations of relavent groups for all reactions) by (3 distances) \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, family, rmg_database, path = None):\n",
    "        \n",
    "        if path is not None:\n",
    "            self.path = path\n",
    "        else:\n",
    "            self.path = os.path.join(os.path.expandvars(\"$RMGpy\"), \"..\", \"AutoTST\", \"database\", family)\n",
    "            \n",
    "        self.family = family\n",
    "        \n",
    "        self.set_TS_training_data(rmg_database)\n",
    "        \n",
    "        self.update_indices()\n",
    "        self.set_group_info()\n",
    "        self.initialize_entry_attributes()\n",
    "        self.adjust_distances()\n",
    "        self.set_entry_data()\n",
    "\n",
    "    \n",
    "    def set_TS_training_data(self, rmg_database):\n",
    "        \"\"\"\n",
    "        Loads Database, sets it as class attribute, sets training_set from database\n",
    "        \"\"\"\n",
    "        from autotst.database import DistanceData, TransitionStateDepository, TSGroups, TransitionStates\n",
    "        ts_database = TransitionStates()\n",
    "        #path = os.path.join(os.path.expandvars(\"$RMGpy\"), \"..\", \"AutoTST\", \"database\", self.family)\n",
    "        path = self.path\n",
    "        global_context = { '__builtins__': None }\n",
    "        local_context={'DistanceData': DistanceData}\n",
    "        assert self.family in rmg_database.kinetics.families.keys(), \"{} not found in kinetics families. Could not Load\".format(family)\n",
    "        family = rmg_database.kinetics.families[self.family]\n",
    "        ts_database.family = family\n",
    "        ts_database.load(path, local_context, global_context)\n",
    "        self.database = ts_database\n",
    "        # Reaction must be a template reaction... found above\n",
    "        \n",
    "        logging.info(\"Getting Training Data for {}\".format(family))\n",
    "        training_data = [ (entry.item, entry.data.distances) for entry in list(ts_database.depository.entries.itervalues())]\n",
    "        self.training_set = training_data\n",
    "        logging.info(\"Total Distances Count: {}\".format(len(self.training_set)))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def update_indices(self):\n",
    "        \"\"\"\n",
    "        Updating entry indices based off of tree indices, tree indices are found by descending the tree\n",
    "        Without this, indices will be based off of previous database which may not be aligned by the current tree\n",
    "        \"\"\"\n",
    "        all_entries = []\n",
    "        self.top_nodes = self.database.groups.top\n",
    "        assert len(self.top_nodes) == 2, 'Only set to work for trees with two top nodes. It has: {}'.format(len(self.top_nodes))\n",
    "        \n",
    "        for top_node in self.top_nodes:\n",
    "            descendants = [top_node] + self.database.groups.descendants(top_node)\n",
    "            all_entries.extend(descendants)\n",
    "\n",
    "        for tree_index, entry in enumerate(all_entries):\n",
    "            #tree_indices[entry] = tree_index\n",
    "            self.database.groups.entries[entry.label].index = tree_index\n",
    "            entry.index = tree_index\n",
    "        \n",
    "        self.all_entries = all_entries\n",
    "        logging.info(\"Updating Indices based off of Tree...\")\n",
    "        logging.info(\"Tree size: {}\".format(len(all_entries)))\n",
    "        return\n",
    "\n",
    "\n",
    "    def set_group_info(self):\n",
    "        \"\"\"\n",
    "        Sets useful group info that is used by further class methods\n",
    "        \"\"\"\n",
    "        \n",
    "        #Direct groups are the lowest level node that matches the reactant structure\n",
    "        direct_groups = []\n",
    "        all_reactant_groups = {} #the two groups (template) of the reactants organized by reactions\n",
    "\n",
    "        for reaction, distance_data in self.training_set:\n",
    "            reactant_groups = [] #The groups that represent each reactant - also known as the template\n",
    "            \"\"\"    \n",
    "            for reactant in reaction.reactants:\n",
    "                reactant = reactant.molecule[0]\n",
    "\n",
    "                atoms = list(reactant.getLabeledAtoms().itervalues())\n",
    "                assert atoms is not None\n",
    "\n",
    "                for top_node in self.top_nodes:\n",
    "                    temp_group = self.database.groups.descendTree(reactant, atoms, root=top_node)\n",
    "                    if temp_group is not None:     #Temp_group will only be found using one of the two top_nodes\n",
    "                        reactant_group = temp_group\n",
    "                        break\n",
    "\n",
    "                assert reactant_group is not None\n",
    "\n",
    "                if isinstance(reactant_group, str):\n",
    "                    assert False, \"Versioning control problem: This should be a redundant check, but clearly is not in this case\"\n",
    "                    reactant_group = ts_database.groups.entries[reactant_group]\n",
    "                assert isinstance(reactant_group, Entry)\n",
    "            \"\"\"\n",
    "    \n",
    "            for top_node in self.top_nodes:\n",
    "\n",
    "                for reactant in reaction.reactants:\n",
    "                    if isinstance(reactant, rmgpy.species.Species):\n",
    "                        reactant = reactant.molecule[0]\n",
    "\n",
    "                    atoms = list(reactant.getLabeledAtoms().itervalues())\n",
    "                    assert atoms is not None\n",
    "\n",
    "                    #temp_group = self.database.groups.descendTree(reactant, atoms, root=top_node)\n",
    "                    temp_group = self.database.groups.descendTree(reactant, atoms, root=top_node)\n",
    "                    if temp_group is not None:     #Temp_group will only be found using one of the two top_nodes\n",
    "                        reactant_group = temp_group\n",
    "                        break\n",
    "\n",
    "\n",
    "                reactant_groups.append(reactant_group)        \n",
    "                direct_groups.append(reactant_group)\n",
    "\n",
    "            all_reactant_groups[reaction] = reactant_groups #storing the templates by reaction\n",
    "\n",
    "        direct_groups = list(set(direct_groups))\n",
    "        direct_groups.sort(key=lambda x:x.index)\n",
    "\n",
    "        all_ancestors = {} #Key is group, value is its itself and all its ancestors\n",
    "        for direct_group in direct_groups:\n",
    "            ancestors = [direct_group] + self.database.groups.ancestors(direct_group)\n",
    "            for ancestor in ancestors:\n",
    "                if ancestor in all_ancestors.keys():\n",
    "                    continue\n",
    "                else:\n",
    "                    all_ancestors[ancestor] = [ancestor] + self.database.groups.ancestors(ancestor)\n",
    "\n",
    "        # We need a list of unique nodes that are directly involved in a reaction or the ancestor of a group that is\n",
    "        nodes_to_update = [group for group in all_ancestors if group not in self.top_nodes]\n",
    "        nodes_to_update.sort(key=lambda x:x.index)\n",
    "\n",
    "        #Group info that is needed to simplify following methods\n",
    "        self.direct_groups = direct_groups\n",
    "        self.nodes_to_update = nodes_to_update\n",
    "        self.group_ancestors = all_ancestors\n",
    "        self.reaction_templates = all_reactant_groups\n",
    "        \n",
    "        logging.info('Nodes to Update: {}'.format(len(self.nodes_to_update)))\n",
    "        logging.info(\"Reaction Templates: {}\".format(len(self.reaction_templates)))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def initialize_entry_attributes(self):\n",
    "        \"\"\"\n",
    "        Attributes of each entry, initializing to size of all_entries\n",
    "        \"\"\"\n",
    "        self.groupComments = {}; self.groupCounts = {}; self.groupUncertainties = {}; self.groupValues = {}\n",
    "        for entry in self.all_entries:\n",
    "            self.groupComments[entry] = set()\n",
    "            self.groupCounts[entry] = []\n",
    "            self.groupUncertainties[entry] = []\n",
    "            self.groupValues[entry] = []\n",
    "        return\n",
    "    \n",
    "    def adjust_distances(self):\n",
    "        \"\"\"\n",
    "        Creating A and b of Ax=b\n",
    "        \"\"\"\n",
    "        def getAllCombinations(nodeLists):\n",
    "            \"\"\"\n",
    "            From base.py:\n",
    "            Generate a list of all possible combinations of items in the list of\n",
    "            lists `nodeLists`. Each combination takes one item from each list\n",
    "            contained within `nodeLists`. The order of items in the returned lists\n",
    "            reflects the order of lists in `nodeLists`. For example, if `nodeLists` was\n",
    "            [[A, B, C], [N], [X, Y]], the returned combinations would be\n",
    "            [[A, N, X], [A, N, Y], [B, N, X], [B, N, Y], [C, N, X], [C, N, Y]].\n",
    "            \"\"\"\n",
    "\n",
    "            items = [[]]\n",
    "            for nodeList in nodeLists:\n",
    "                items = [ item + [node] for node in nodeList for item in items ]\n",
    "\n",
    "            return items\n",
    "        ##############################################\n",
    "    \n",
    "        distance_keys = sorted(self.training_set[0][1].keys())\n",
    "        #distance_keys are ['d12', 'd13', 'd23']\n",
    "\n",
    "        A = []\n",
    "        b = []\n",
    "        for reaction, distance_data in self.training_set:\n",
    "            template = self.reaction_templates[reaction]\n",
    "            distances_list = [distance_data[key] for key in distance_keys]\n",
    "\n",
    "            relavent_combinations = []\n",
    "            for reactant_group in template:\n",
    "                relavent_combinations.append(self.group_ancestors[reactant_group])\n",
    "            assert len(relavent_combinations) == 2 #will throw if reaction does not have 2 reactants\n",
    "\n",
    "            relavent_combinations = getAllCombinations(relavent_combinations)\n",
    "            #rel_comb is just all combinations of reactant1 and its ancestors with reactant2 and its ancestors\n",
    "\n",
    "            for combination in relavent_combinations:\n",
    "                Arow = [1 if group in combination else 0 for group in self.nodes_to_update]\n",
    "                Arow.append(1) #For use in finding the family component\n",
    "                #Arow is a binary vector of len(groupList)+1 representing contributing groups to this reaction's distance data\n",
    "                A.append(Arow)\n",
    "                b.append(distances_list)\n",
    "                for group in combination:\n",
    "                    if isinstance(group, str):\n",
    "                        assert False, \"Discrepancy between versions of RMG_Database and this one\"\n",
    "\n",
    "                    self.groupComments[group].add('{0!s}'.format(template))\n",
    "\n",
    "        self.A = numpy.array(A)\n",
    "        self.b = numpy.array(b)\n",
    "        return\n",
    "    \n",
    "    def set_entry_data(self):\n",
    "        \"\"\"\n",
    "        Using A and b to find stats for relavent nodes of tree\n",
    "        \"\"\"\n",
    "        import scipy.stats\n",
    "        # Groups M and N are associated with a reaction that has a known ts geometry\n",
    "        # Groups M, N, and the family component must add together to get as close to that geometry as possible\n",
    "        # M and N are optimized based off of all reactionas they are involved with and the family component is optimized over all reactions of that family\n",
    "\n",
    "\n",
    "        distance_keys = sorted(self.training_set[0][1].keys())\n",
    "        #distance_keys are ['d12', 'd13', 'd23']\n",
    "\n",
    "        x, residuals, rank, s = numpy.linalg.lstsq(self.A, self.b)\n",
    "        for i, distance_key in enumerate(distance_keys):\n",
    "            # Determine error in each group\n",
    "            variance_sums = numpy.zeros(len(self.nodes_to_update)+1, numpy.float64)\n",
    "            stdev = numpy.zeros(len(self.nodes_to_update)+1, numpy.float64)\n",
    "            counts = numpy.zeros(len(self.nodes_to_update)+1, numpy.int)\n",
    "\n",
    "            for reaction, distances in self.training_set:\n",
    "                template = self.reaction_templates[reaction]\n",
    "\n",
    "                distances_list = [distances[key] for key in distance_keys]\n",
    "                d = numpy.float64(distances_list[i])\n",
    "                #dm found by manually summing residuals\n",
    "                dm = x[-1,i] + sum([x[self.nodes_to_update.index(group),i] for group in template])\n",
    "\n",
    "\n",
    "                variance = (dm - d)**2\n",
    "\n",
    "                for group in template:\n",
    "                    for ancestor in self.group_ancestors[group]:\n",
    "                        if ancestor not in self.top_nodes:\n",
    "                            ind = self.nodes_to_update.index(ancestor)\n",
    "                            variance_sums[ind] += variance\n",
    "                            counts[ind] += 1\n",
    "                variance_sums[-1] += variance\n",
    "                counts[-1] += 1\n",
    "                \n",
    "            ci = numpy.zeros(len(counts))\n",
    "\n",
    "            for j, count in enumerate(counts):\n",
    "                if count > 2:\n",
    "                    stdev[j] = numpy.sqrt(variance_sums[j] / (count - 1))\n",
    "                    ci[j] = scipy.stats.t.ppf(0.975, count - 1) * stdev[j]\n",
    "                else:\n",
    "                    stdev[j] = None\n",
    "                    ci[j] = None\n",
    "\n",
    "            # Update dictionaries of fitted group values and uncertainties\n",
    "            for entry in self.all_entries:\n",
    "                if entry == self.top_nodes[0]:\n",
    "                    self.groupValues[entry].append(x[-1, i])\n",
    "                    self.groupUncertainties[entry].append(ci[-1])\n",
    "                    self.groupCounts[entry].append(counts[-1])\n",
    "                elif entry.label in [group.label for group in self.nodes_to_update]:\n",
    "                    index = self.nodes_to_update.index(entry)\n",
    "                    \n",
    "                    self.groupValues[entry].append(x[index,i])\n",
    "                    self.groupUncertainties[entry].append(ci[index])\n",
    "                    self.groupCounts[entry].append(counts[index])\n",
    "                else:\n",
    "                    self.groupValues[entry] = None\n",
    "                    self.groupUncertainties[entry] = None\n",
    "                    self.groupCounts[entry] = None\n",
    "            \n",
    "            for entry in self.all_entries:\n",
    "                if self.groupValues[entry] is not None:\n",
    "                    if not any(numpy.isnan(numpy.array(self.groupUncertainties[entry]))):\n",
    "                        # should be entry.data.* (e.g. entry.data.uncertainties)\n",
    "                        uncertainties = numpy.array(self.groupUncertainties[entry])\n",
    "                        uncertaintyType = '+|-'\n",
    "                    else:\n",
    "                        uncertainties = {}\n",
    "                    # should be entry.*\n",
    "                    shortDesc = \"Fitted to {0} distances.\\n\".format(self.groupCounts[entry][0])\n",
    "                    longDesc = \"\\n\".join(self.groupComments[entry])\n",
    "                    distances_dict = {key:distance for key, distance in zip(distance_keys, self.groupValues[entry])}\n",
    "                    uncertainties_dict = {key:distance for key, distance in zip(distance_keys, uncertainties)}\n",
    "                    \n",
    "                    entry.data = DistanceData(distances=distances_dict, uncertainties=uncertainties_dict)\n",
    "                    entry.shortDesc = shortDesc\n",
    "                    entry.longDesc = longDesc\n",
    "                else:\n",
    "                    entry.data = DistanceData()\n",
    "                    entry.longDesc = ''\n",
    "        logging.info(\"Finished Updating Entries for {}\\n\".format(self.family))\n",
    "        return\n",
    "        \n",
    "    def save_database(self, path = None):\n",
    "        if path is None and self.path is None:\n",
    "            logging.error(\"Need path to save output\")\n",
    "        elif path is None:\n",
    "            path = os.join(self.path, 'TS_groups.py')\n",
    "\n",
    "        self.database.saveTransitionStateGroups(path)\n",
    "        logging.info('Saved {} Database to: {}'.format(self.family, path))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Should only make one instance of RMGDatabase because it's stored as a module-level variable!\n",
      "WARNING:root:Unexpected behaviour may result!\n",
      "ERROR:root:Error while reading database 'C:\\\\Users\\\\carle\\\\Code\\\\RMG-Py\\\\..\\\\RMG-database\\\\input\\\\thermo\\\\groups\\\\group.py'.\n",
      "ERROR:root:Failed to Load RMG Database at C:\\Users\\carle\\Code\\RMG-Py\\..\\RMG-database\\input\n"
     ]
    }
   ],
   "source": [
    "x = TS_Database_Update(['H_Abstraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "master_list = []\n",
    "for value in ts_database.groups.entries.values():\n",
    "    #print value.data\n",
    "    \n",
    "    if not value.data.distances == {}:\n",
    "        master_list.append(value)\n",
    "        count += 1\n",
    "print \"Master: {}\".format(count)\n",
    "#master_list\n",
    "\n",
    "count = 0\n",
    "second_list = []\n",
    "for value in x.database.groups.entries.values():\n",
    "    #print value.data\n",
    "    \n",
    "    if not value.data.distances == {}:\n",
    "        second_list.append(value)\n",
    "        count += 1\n",
    "print \"Secondary: {}\".format(count)\n",
    "print\n",
    "#second_list \n",
    "\n",
    "for e in master_list:\n",
    "    if not e in second_list:\n",
    "        print e\n",
    "        \n",
    "for ee in second_list:\n",
    "    if not ee in master_list:\n",
    "        print ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Should only make one instance of RMGDatabase because it's stored as a module-level variable!\n",
      "WARNING:root:Unexpected behaviour may result!\n",
      "ERROR:root:Error while reading database 'C:\\\\Users\\\\carle\\\\Code\\\\RMG-Py\\\\..\\\\RMG-database\\\\input\\\\thermo\\\\groups\\\\group.py'.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'O2s'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d85fffa6ed79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                  \u001b[0mseedMechanisms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                  \u001b[0mthermoLibraries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'primaryThermoLibrary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'thermo_DFT_CCSDTF12_BAC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CBS_QB3_1dHR'\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                  \u001b[0msolvation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m                  )\n",
      "\u001b[1;32mC:\\Users\\carle\\Code\\RMG-Py\\rmgpy\\data\\rmg.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, path, thermoLibraries, transportLibraries, reactionLibraries, seedMechanisms, kineticsFamilies, kineticsDepositories, statmechLibraries, depository, solvation, testing)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mArgument\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mload\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlighter\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdatabase\u001b[0m \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtests\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \"\"\"\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadThermo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'thermo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthermoLibraries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepository\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtesting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadTransport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'transport'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransportLibraries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carle\\Code\\RMG-Py\\rmgpy\\data\\rmg.pyc\u001b[0m in \u001b[0;36mloadThermo\u001b[1;34m(self, path, thermoLibraries, depository)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \"\"\"\n\u001b[0;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthermo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mThermoDatabase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthermo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthermoLibraries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepository\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthermo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'thermo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carle\\Code\\RMG-Py\\rmgpy\\data\\thermo.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, path, libraries, depository)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepository\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadLibraries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'libraries'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibraries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadGroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'groups'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecordRingGenericNodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carle\\Code\\RMG-Py\\rmgpy\\data\\thermo.pyc\u001b[0m in \u001b[0;36mloadGroups\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    806\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loading thermodynamics group database from {0}...'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'group'\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;33m=\u001b[0m   \u001b[0mThermoGroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'group'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'group.py'\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ring'\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;33m=\u001b[0m    \u001b[0mThermoGroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ring'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ring.py'\u001b[0m   \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'radical'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mThermoGroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'radical'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'radical.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carle\\Code\\RMG-Py\\rmgpy\\data\\base.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, path, local_context, global_context)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m             \u001b[1;32mexec\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglobal_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Error while reading database {0!r}.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carle\\Code\\RMG-Py\\..\\RMG-database\\input\\thermo\\groups\\group.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    190\u001b[0m u\"\"\"\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m \"\"\",\n\u001b[0m\u001b[0;32m    193\u001b[0m )\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carle\\Code\\RMG-Py\\rmgpy\\data\\thermo.pyc\u001b[0m in \u001b[0;36mloadEntry\u001b[1;34m(self, index, label, group, thermo, reference, referenceType, shortDesc, longDesc, rank)\u001b[0m\n\u001b[0;32m    615\u001b[0m             \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakeLogicNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m             \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromAdjacencyList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m         self.entries[label] = Entry(\n\u001b[0;32m    619\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carle\\Code\\RMG-Py\\rmgpy\\molecule\\group.pyd\u001b[0m in \u001b[0;36mrmgpy.molecule.group.Group.fromAdjacencyList\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carle\\Code\\RMG-Py\\rmgpy\\molecule\\group.pyd\u001b[0m in \u001b[0;36mrmgpy.molecule.group.Group.fromAdjacencyList\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carle\\Code\\RMG-Py\\rmgpy\\molecule\\adjlist.pyc\u001b[0m in \u001b[0;36mfromAdjacencyList\u001b[1;34m(adjlist, group, saturateH)\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;31m# Create a new atom based on the above information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             \u001b[0matom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGroupAtom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0matomType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munpairedElectrons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartialCharges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlonePairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[0matom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAtom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0matomType\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munpairedElectrons\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartialCharges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlonePairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carle\\Code\\RMG-Py\\rmgpy\\molecule\\group.pyd\u001b[0m in \u001b[0;36mrmgpy.molecule.group.GroupAtom.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'O2s'"
     ]
    }
   ],
   "source": [
    "rmg_database = RMGDatabase()\n",
    "database_path = os.path.join(os.path.expandvars('$RMGpy'), \"..\",  'RMG-database', 'input')\n",
    "rmg_database.load(database_path,\n",
    "                 kineticsFamilies=['H_Abstraction'],\n",
    "                 transportLibraries=[],\n",
    "                 reactionLibraries=[],\n",
    "                 seedMechanisms=[],\n",
    "                 thermoLibraries=['primaryThermoLibrary', 'thermo_DFT_CCSDTF12_BAC', 'CBS_QB3_1dHR' ],\n",
    "                 solvation=False,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_TS_training_data():\n",
    "    from autotst.database import DistanceData, TransitionStateDepository, TSGroups, TransitionStates\n",
    "    rmg_database = RMGDatabase()\n",
    "    database_path = os.path.join(os.path.expandvars('$RMGpy'), \"..\",  'RMG-database', 'input')\n",
    "    rmg_database.load(database_path,\n",
    "                     kineticsFamilies=['H_Abstraction'],\n",
    "                     transportLibraries=[],\n",
    "                     reactionLibraries=[],\n",
    "                     seedMechanisms=[],\n",
    "                     thermoLibraries=['primaryThermoLibrary', 'thermo_DFT_CCSDTF12_BAC', 'CBS_QB3_1dHR' ],\n",
    "                     solvation=False,\n",
    "                     )\n",
    "\n",
    "    ts_database = TransitionStates()\n",
    "    path = os.path.join(os.path.expandvars(\"$RMGpy\"), \"..\", \"AutoTST\", \"database\", \"H_Abstraction\")\n",
    "    global_context = { '__builtins__': None }\n",
    "    local_context={'DistanceData': DistanceData}\n",
    "    family = rmg_database.kinetics.families[\"H_Abstraction\"]\n",
    "    ts_database.family = family\n",
    "    ts_database.load(path, local_context, global_context)\n",
    "\n",
    "    # Reaction must be a template reaction... found above\n",
    "\n",
    "    training_set = [ (entry.item, entry.data.distances) for entry in list(ts_database.depository.entries.itervalues())]\n",
    "    print \"Total Distances Count: {}\".format(len(training_set))\n",
    "    return training_set, ts_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def update_indices(database):\n",
    "    # Updating entry indices based off of tree indices, tree indices are found by descending the tree\n",
    "    all_entries = []\n",
    "    top_nodes = database.groups.top\n",
    "    for top_node in top_nodes:\n",
    "        descendants = [top_node] + database.groups.descendants(top_node)\n",
    "        all_entries.extend(descendants)\n",
    "    #tree_indices = {}\n",
    "    for tree_index, entry in enumerate(all_entries):\n",
    "        #tree_indices[entry] = tree_index\n",
    "        database.groups.entries[entry.label].index = tree_index\n",
    "        entry.index = tree_index\n",
    "    print \"Tree size: {}\".format(len(all_entries))\n",
    "    #list(ts_database.groups.entries.keys())\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewrite not using products, not using top_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "#All the direct groups we have data for\n",
    "direct_groups = []\n",
    "all_reactant_groups = {} #templates organized by reaction\n",
    "\n",
    "for reaction, distance_data in training_set:\n",
    "    reactant_groups = []\n",
    "    #The groups that represent each reactant - also known as the template\n",
    "    for reactant in reaction.reactants:\n",
    "        reactant = reactant.molecule[0]\n",
    "        \n",
    "        atoms = list(reactant.getLabeledAtoms().itervalues())\n",
    "        assert atoms is not None\n",
    "        \n",
    "        for top_node in top_nodes:\n",
    "            temp_group = ts_database.groups.descendTree(reactant, atoms, root=top_node)\n",
    "            if temp_group is not None:\n",
    "                reactant_group = temp_group\n",
    "                continue\n",
    "        \n",
    "        assert reactant_group is not None\n",
    "        \n",
    "        if isinstance(reactant_group, str):\n",
    "            assert False, \"why? {}\".format(reactant_group)\n",
    "            reactant_group = ts_database.groups.entries[reactant_group]\n",
    "        assert isinstance(reactant_group, Entry)\n",
    "\n",
    "        reactant_groups.append(reactant_group)        \n",
    "        direct_groups.append(reactant_group)\n",
    "        \n",
    "    all_reactant_groups[reaction] = reactant_groups\n",
    "    \n",
    "direct_groups = list(set(direct_groups))\n",
    "direct_groups.sort(key=lambda x:x.index)\n",
    "\n",
    "all_ancestors = {} #Key is group, value is its itself and all its ancestors\n",
    "for direct_group in direct_groups:\n",
    "    ancestors = [direct_group] + ts_database.groups.ancestors(direct_group)\n",
    "    for ancestor in ancestors:\n",
    "        if ancestor in all_ancestors.keys():\n",
    "            continue\n",
    "        else:\n",
    "            all_ancestors[ancestor] = [ancestor] + ts_database.groups.ancestors(ancestor)\n",
    "\n",
    "nodes_to_update = [group for group in all_ancestors if group not in top_nodes]\n",
    "nodes_to_update.sort(key=lambda x:x.index)\n",
    "\n",
    "print 'Nodes to Update: {}'.format(len(nodes_to_update))\n",
    "print \"Reaction Templates: {}\".format(len(all_reactant_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test case to see if all_ancestors is working properly\n",
    "goal = 'C_methane'\n",
    "entry = None\n",
    "for item in all_entries:\n",
    "    #print item.label\n",
    "    if item.label == goal:\n",
    "        entry = item\n",
    "if entry is not None:\n",
    "    #if isinstance(entry, str):\n",
    "    #    entry = ts_database.groups.entries[entry]\n",
    "    print entry\n",
    "    ancestors = ts_database.groups.ancestors(entry)\n",
    "print ancestors\n",
    "print all_ancestors[entry][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stolen from base.py\n",
    "def getAllCombinations(nodeLists):\n",
    "    \"\"\"\n",
    "    Generate a list of all possible combinations of items in the list of\n",
    "    lists `nodeLists`. Each combination takes one item from each list\n",
    "    contained within `nodeLists`. The order of items in the returned lists\n",
    "    reflects the order of lists in `nodeLists`. For example, if `nodeLists` was\n",
    "    [[A, B, C], [N], [X, Y]], the returned combinations would be\n",
    "    [[A, N, X], [A, N, Y], [B, N, X], [B, N, Y], [C, N, X], [C, N, Y]].\n",
    "    \"\"\"\n",
    "\n",
    "    items = [[]]\n",
    "    for nodeList in nodeLists:\n",
    "        items = [ item + [node] for node in nodeList for item in items ]\n",
    "\n",
    "    return items\n",
    "##############################################\n",
    "#for entry in ts_database.groups.entries:\n",
    "#    ts_database.groups.entries[entry].training_data = []\n",
    "\n",
    "\n",
    "#Attributes of each entry\n",
    "groupComments = {}; groupCounts = {}; groupUncertainties = {}; groupValues = {}\n",
    "for entry in all_entries:\n",
    "    groupComments[entry] = set()\n",
    "    groupCounts[entry] = []\n",
    "    groupUncertainties[entry] = []\n",
    "    groupValues[entry] = []\n",
    "\n",
    "#distance_keys = sorted(training_set[0][1].keys())\n",
    "distance_keys = ['d12', 'd13', 'd23']\n",
    "\n",
    "#all_updated = []\n",
    "A = []\n",
    "b = []\n",
    "for reaction, distance_data in training_set:\n",
    "    template = all_reactant_groups[reaction]\n",
    "    distances_list = [distance_data[key] for key in distance_keys]\n",
    "    #distance_data = numpy.array(distance_list)\n",
    "    relavent_combinations = []\n",
    "    for reactant_group in all_reactant_groups[reaction]:\n",
    "        relavent_combinations.append(all_ancestors[reactant_group])\n",
    "    assert len(relavent_combinations) == 2 #will throw if reaction does not have 2 reactants\n",
    "        \n",
    "    relavent_combinations = getAllCombinations(relavent_combinations)\n",
    "    #rel_comb is just all combinations of reactant1 and its ancestors with reactant2 and its ancestors\n",
    "    \n",
    "    for combination in relavent_combinations:\n",
    "        Arow = [1 if group in combination else 0 for group in nodes_to_update]\n",
    "        Arow.append(1) #For use in finding the family component\n",
    "        #Arow is a binary vector of len(groupList)+1 representing contributing groups to this reaction's distance data\n",
    "        A.append(Arow)\n",
    "        b.append(distances_list)\n",
    "        for group in combination:\n",
    "            if isinstance(group, str):\n",
    "                assert False\n",
    "                group = self.entries[group]\n",
    "\n",
    "            groupComments[group].add('{0!s}'.format(template))\n",
    "\n",
    "A = numpy.array(A)\n",
    "b = numpy.array(b)\n",
    "\n",
    "#######################################################################\n",
    "# What I think is going on:\n",
    "# Groups M and N are associated with a reaction that produces distances, they are differences from the family contribution\n",
    "# Groups M, N, and the family contribution must add together in some manner to get as close to this distance, as well as in all other reactions of different combinations\n",
    "# Design matrix of size (All possible group combinations for all possible reactions) by (all groups + 1). Last row is needed for family contribution\n",
    "    \n",
    "#distance_keys = sorted(training_set[0][1].distance.keys())\n",
    "#distance_keys = ['d12', 'd13', 'd23']\n",
    "\n",
    "x, residuals, rank, s = numpy.linalg.lstsq(A, b)\n",
    "for i, distance_key in enumerate(distance_keys):\n",
    "    # Determine error in each group\n",
    "    variance_sums = numpy.zeros(len(nodes_to_update)+1, numpy.float64)\n",
    "    stdev = numpy.zeros(len(nodes_to_update)+1, numpy.float64)\n",
    "    counts = numpy.zeros(len(nodes_to_update)+1, numpy.int)\n",
    "\n",
    "    #it seems convoluted but it creates a list of variances for all entries in groups entries\n",
    "    #the last item of the list is the sum of variances for the entire list which represents the entry\n",
    "\n",
    "    #for index in range(len(trainingSet)):\n",
    "    #for index, [reaction, distances] in enumerate(trainingSet):\n",
    "    for reaction, distances in training_set:\n",
    "        template = all_reactant_groups[reaction]\n",
    "        \n",
    "        distances_list = [distance_data[key] for key in distance_keys]\n",
    "        d = numpy.float64(distances_list[i])\n",
    "        dm = x[-1,i] + sum([x[nodes_to_update.index(group),i] for group in template]) #if group in nodes_to_update])\n",
    "        \n",
    "        #TODO remove:\n",
    "        for group in template:\n",
    "            assert group in nodes_to_update\n",
    "        \n",
    "        variance = (dm - d)**2\n",
    "        \n",
    "        for group in template:\n",
    "            for ancestor in all_ancestors[group]:\n",
    "                if ancestor not in top_nodes:\n",
    "                    ind = nodes_to_update.index(ancestor)\n",
    "                    variance_sums[ind] += variance\n",
    "                    counts[ind] += 1\n",
    "        variance_sums[-1] += variance\n",
    "        counts[-1] += 1\n",
    "\n",
    "    import scipy.stats\n",
    "    ci = numpy.zeros(len(counts))\n",
    "    #for i in range(len(count)):\n",
    "    for j, count in enumerate(counts):\n",
    "        if count > 2:\n",
    "            stdev[j] = numpy.sqrt(variance_sums[j] / (count - 1))\n",
    "            ci[j] = scipy.stats.t.ppf(0.975, count - 1) * stdev[j]\n",
    "            #'probability density function'\n",
    "        else:\n",
    "            stdev[j] = None\n",
    "            ci[j] = None\n",
    "    \n",
    "    # Update dictionaries of fitted group values and uncertainties\n",
    "    for entry in all_entries:\n",
    "        if entry == top_nodes[0]:\n",
    "            groupValues[entry].append(x[-1, i])\n",
    "            groupUncertainties[entry].append(ci[-1])\n",
    "            groupCounts[entry].append(counts[-1])\n",
    "        elif entry.label in [group.label for group in nodes_to_update]:\n",
    "            #index = [group.label for group in groupList].index(entry.label)\n",
    "            index = nodes_to_update.index(entry)\n",
    "            groupValues[entry].append(x[index,i])\n",
    "            groupUncertainties[entry].append(ci[index])\n",
    "            groupCounts[entry].append(counts[index])\n",
    "        else:\n",
    "            groupValues[entry] = None\n",
    "            groupUncertainties[entry] = None\n",
    "            groupCounts[entry] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for entry in all_entries:\n",
    "    print entry.label\n",
    "    print groupValues[entry]\n",
    "    print groupUncertainties[entry]\n",
    "    print len(groupComments[entry])\n",
    "    break\n",
    "print\n",
    "for entry in all_entries:\n",
    "    if entry.index == 5:\n",
    "        print entry.label\n",
    "        print groupValues[entry]\n",
    "        print groupUncertainties[entry]\n",
    "        print len(groupComments[entry])\n",
    "        break\n",
    "\n",
    "\"\"\"neg = []\n",
    "all_neg = []\n",
    "impossible = []\n",
    "for entry in groupValues:\n",
    "    distances = groupValues[entry]\n",
    "    uncertainties = groupUncertainties[entry]\n",
    "    if distances is not None:\n",
    "        has_neg = False\n",
    "        has_all_neg = False\n",
    "        #Impossible ones have negative distances and uncertainties too small to create a range with positive values\n",
    "        is_impossible = False\n",
    "        \n",
    "        if distances[0] < 0 or distances[1] < 0 or distances[2] < 0:\n",
    "            has_neg = True\n",
    "        \n",
    "        if distances[0] < 0 and distances[1] < 0 and distances[2] < 0:\n",
    "            has_all_neg = True\n",
    "        \n",
    "        if distances[0] < 0 and distances[0] + uncertainties[0] < 0:\n",
    "            is_impossible = True\n",
    "        \n",
    "        if distances[1] < 0 and distances[1] + uncertainties[1] < 0:\n",
    "            is_impossible = True\n",
    "        \n",
    "        if distances[2] < 0 and distances[2] + uncertainties[2] < 0:\n",
    "            is_impossible = True\n",
    "        \n",
    "        if has_neg:\n",
    "            neg.append(entry)\n",
    "        if has_all_neg:\n",
    "            all_neg.append(entry)\n",
    "        if is_impossible:\n",
    "            impossible.append(entry)\n",
    "print\n",
    "print \"Atleast one negative: {}\".format(len(neg))\n",
    "print \"All negative: {}\".format(len(all_neg))\n",
    "print \"Negative and too small uncertainty: {}\".format(len(impossible))\"\"\"\n",
    "\n",
    "print\n",
    "print nodes_to_update[13]\n",
    "print counts[13]\n",
    "print ci[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for entry in groupUncertainties:\n",
    "    if groupUncertainties[entry] is not None:\n",
    "        count += 1\n",
    "        print \"{}   \\t:\\t{}\".format(entry, groupUncertainties[entry])\n",
    "print\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atomList = []\n",
    "for top_node in top_nodes:\n",
    "    group = top_node.item\n",
    "    print group\n",
    "    if isinstance(top_node.item, LogicNode):\n",
    "        group = top_node.item.getPossibleStructures(ts_database.groups.entries)[0]\n",
    "    top_node_atoms = group.getLabeledAtoms()\n",
    "    atomList.extend([top_node_atoms])\n",
    "\n",
    "atomList = atomList[1]\n",
    "atomList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################\n",
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using top_nodes, no products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "#All the direct groups we have data for\n",
    "direct_groups = []\n",
    "all_reactant_groups = {} #templates organized by reaction\n",
    "\n",
    "for reaction, distance_data in training_set:\n",
    "    reactant_groups = []\n",
    "    #The groups that represent each reactant - also known as the template\n",
    "    for reactant in reaction.reactants:\n",
    "        reactant = reactant.molecule[0]\n",
    "        \n",
    "        atoms = list(reactant.getLabeledAtoms().itervalues())\n",
    "        assert atoms is not None\n",
    "        \n",
    "        for top_node in top_nodes:\n",
    "            temp_group = ts_database.groups.descendTree(reactant, atoms, root=top_node)\n",
    "            if temp_group is not None:\n",
    "                reactant_group = temp_group\n",
    "                continue\n",
    "        \n",
    "        assert reactant_group is not None\n",
    "        \n",
    "        if isinstance(reactant_group, str):\n",
    "            assert False, \"why? {}\".format(reactant_group)\n",
    "            reactant_group = ts_database.groups.entries[reactant_group]\n",
    "        assert isinstance(reactant_group, Entry)\n",
    "\n",
    "        reactant_groups.append(reactant_group)        \n",
    "        direct_groups.append(reactant_group)\n",
    "        \n",
    "    all_reactant_groups[reaction] = reactant_groups\n",
    "    \n",
    "direct_groups = list(set(direct_groups))\n",
    "direct_groups.sort(key=lambda x:x.index)\n",
    "\n",
    "all_ancestors = {} #Key is group, value is its itself and all its ancestors\n",
    "for direct_group in direct_groups:\n",
    "    ancestors = [direct_group] + ts_database.groups.ancestors(direct_group)\n",
    "    for ancestor in ancestors:\n",
    "        if ancestor in all_ancestors.keys():\n",
    "            continue\n",
    "        else:\n",
    "            all_ancestors[ancestor] = [ancestor] + ts_database.groups.ancestors(ancestor)\n",
    "\n",
    "nodes_to_update = [group for group in all_ancestors]\n",
    "nodes_to_update.sort(key=lambda x:x.index)\n",
    "\n",
    "print 'Nodes to Update: {}'.format(len(nodes_to_update))\n",
    "print \"All Reactant Groups: {}\".format(len(all_reactant_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#for entry in ts_database.groups.entries:\n",
    "#    ts_database.groups.entries[entry].training_data = []\n",
    "\n",
    "#Attributes of each entry\n",
    "groupComments = {}; groupCounts = {}; groupUncertainties = {}; groupValues = {}\n",
    "for entry in all_entries:\n",
    "    groupComments[entry] = set()\n",
    "    groupCounts[entry] = []\n",
    "    groupUncertainties[entry] = []\n",
    "    groupValues[entry] = []\n",
    "\n",
    "#distance_keys = sorted(training_set[0][1].keys())\n",
    "distance_keys = ['d12', 'd13', 'd23']\n",
    "\n",
    "#all_updated = []\n",
    "A = []\n",
    "B = []\n",
    "for reaction, distance_data in training_set:\n",
    "    template = all_reactant_groups[reaction]\n",
    "    distances_list = [distance_data[key] for key in distance_keys]\n",
    "    #distance_data = numpy.array(distance_list)\n",
    "    relavent_combinations = []\n",
    "    for reactant_group in all_reactant_groups[reaction]:\n",
    "        relavent_combinations.append(all_ancestors[reactant_group])\n",
    "    assert len(relavent_combinations) == 2 #will throw if reaction does not have 2 reactants\n",
    "        \n",
    "    relavent_combinations = getAllCombinations(relavent_combinations)\n",
    "    #rel_comb is just all combinations of reactant1 and its ancestors with reactant2 and its ancestors\n",
    "    \n",
    "    for combination in relavent_combinations:\n",
    "        Arow = [1 if group in combination else 0 for group in nodes_to_update]\n",
    "        Arow.append(1)\n",
    "        #Arow is a binary vector of len(groupList)+1 representing contributing groups to this reaction's distance data\n",
    "        A.append(Arow)\n",
    "        B.append(distances_list)\n",
    "        for group in combination:\n",
    "            if isinstance(group, str):\n",
    "                assert False\n",
    "                group = self.entries[group]\n",
    "\n",
    "            groupComments[group].add('{0!s}'.format(template))\n",
    "print \"Length of A: {}\".format(len(A))\n",
    "print\n",
    "\n",
    "A = numpy.array(A)\n",
    "B = numpy.array(B)\n",
    "\n",
    "#######################################################################\n",
    "# What I think is going on:\n",
    "# Groups M and N are associated with a reaction that produces distances\n",
    "# Groups M and N must add together in some manner to get as close to this distance as well as in all other reactions of different combinations\n",
    "# Design matrix of size (All possible group combinations for all possible reactions) by (all groups + 1). Last row is needed for intercept\n",
    "    \n",
    "#distance_keys = sorted(training_set[0][1].distance.keys())\n",
    "#distance_keys = ['d12', 'd13', 'd23']\n",
    "\n",
    "x, residuals, rank, s = numpy.linalg.lstsq(A, B)\n",
    "for i, distance_key in enumerate(distance_keys):\n",
    "    # Determine error in each group\n",
    "    variance_sums = numpy.zeros(len(nodes_to_update)+1, numpy.float64)\n",
    "    stdev = numpy.zeros(len(nodes_to_update)+1, numpy.float64)\n",
    "    counts = numpy.zeros(len(nodes_to_update)+1, numpy.int)\n",
    "\n",
    "    #it seems convoluted but it creates a list of variances for all entries in groups entries\n",
    "    #the last item of the list is the sum of variances for the entire list which represents the entry\n",
    "\n",
    "    #for index in range(len(trainingSet)):\n",
    "    #for index, [reaction, distances] in enumerate(trainingSet):\n",
    "    for reaction, distances in training_set:\n",
    "        template = all_reactant_groups[reaction]\n",
    "        \n",
    "        distances_list = [distance_data[key] for key in distance_keys]\n",
    "        d = numpy.float64(distances_list[i])\n",
    "        dm = x[-1,i] + sum([x[nodes_to_update.index(group),i] for group in template if group in nodes_to_update])\n",
    "        \n",
    "        variance = (dm - d)**2\n",
    "        \n",
    "        for group in template:\n",
    "            for ancestor in all_ancestors[group]:\n",
    "                #if ancestor not in top_nodes:\n",
    "                ind = nodes_to_update.index(ancestor)\n",
    "                variance_sums[ind] += variance\n",
    "                counts[ind] += 1\n",
    "        variance_sums[-1] += variance\n",
    "        counts[-1] += 1\n",
    "\n",
    "    #import scipy.stats\n",
    "    ci = numpy.zeros(len(counts))\n",
    "    #for i in range(len(count)):\n",
    "    for j, count in enumerate(counts):\n",
    "        if count > 1:\n",
    "            stdev[j] = numpy.sqrt(variance_sums[j] / (count - 1))\n",
    "            ci[j] = scipy.stats.t.ppf(0.975, count - 1) * stdev[j]\n",
    "            #'probability density function'\n",
    "        else:\n",
    "            stdev[j] = None\n",
    "            ci[j] = None\n",
    "    \n",
    "    # Update dictionaries of fitted group values and uncertainties\n",
    "    for entry in all_entries:\n",
    "        \"\"\"if entry == top_nodes[0]:\n",
    "            groupValues[entry].append(x[-1, i])\n",
    "            groupUncertainties[entry].append(ci[-1])\n",
    "            groupCounts[entry].append(counts[-1])\"\"\"\n",
    "        if entry.label in [group.label for group in nodes_to_update]:\n",
    "            #index = [group.label for group in groupList].index(entry.label)\n",
    "            index = nodes_to_update.index(entry)\n",
    "            groupValues[entry].append(x[index,i])\n",
    "            groupUncertainties[entry].append(ci[index])\n",
    "            groupCounts[entry].append(counts[index])\n",
    "        else:\n",
    "            groupValues[entry] = None\n",
    "            groupUncertainties[entry] = None\n",
    "            groupCounts[entry] = None\n",
    "\n",
    "for entry in all_entries:\n",
    "    print entry.label\n",
    "    print groupValues[entry]\n",
    "    print groupUncertainties[entry]\n",
    "    print len(groupComments[entry])\n",
    "    break\n",
    "print\n",
    "for entry in all_entries:\n",
    "    if entry.index == 5:\n",
    "        print entry.label\n",
    "        print groupValues[entry]\n",
    "        print groupUncertainties[entry]\n",
    "        print len(groupComments[entry])\n",
    "        break\n",
    "        \n",
    "has_neg_distances = [entry for entry in all_entries if value < 0 for value in groupValues[entry]]\n",
    "print len(has_neg_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "#All the direct groups we have data for\n",
    "direct_groups = []\n",
    "all_reactant_groups = {} #templates organized by reaction\n",
    "\n",
    "for reaction, distance_data in training_set:\n",
    "    reactant_groups = []\n",
    "    #The groups that represent each reactant - also known as the template\n",
    "    for reactant in reaction.reactants:\n",
    "        reactant = reactant.molecule[0]\n",
    "        \n",
    "        atoms = list(reactant.getLabeledAtoms().itervalues())\n",
    "        assert atoms is not None\n",
    "        \n",
    "        for top_node in top_nodes:\n",
    "            temp_group = ts_database.groups.descendTree(reactant, atoms, root=top_node)\n",
    "            if temp_group is not None:\n",
    "                reactant_group = temp_group\n",
    "                continue\n",
    "        \n",
    "        assert reactant_group is not None\n",
    "        \n",
    "        if isinstance(reactant_group, str):\n",
    "            assert False, \"why? {}\".format(reactant_group)\n",
    "            reactant_group = ts_database.groups.entries[reactant_group]\n",
    "        assert isinstance(reactant_group, Entry)\n",
    "\n",
    "        reactant_groups.append(reactant_group)        \n",
    "        direct_groups.append(reactant_group)\n",
    "        \n",
    "    all_reactant_groups[reaction] = reactant_groups\n",
    "    \n",
    "direct_groups = list(set(direct_groups))\n",
    "direct_groups.sort(key=lambda x:x.index)\n",
    "\n",
    "all_ancestors = {} #Key is group, value is its itself and all its ancestors\n",
    "for direct_group in direct_groups:\n",
    "    ancestors = [direct_group] + ts_database.groups.ancestors(direct_group)[:-1]\n",
    "    for ancestor in ancestors:\n",
    "        if ancestor in all_ancestors.keys():\n",
    "            continue\n",
    "        else:\n",
    "            all_ancestors[ancestor] = [ancestor] + ts_database.groups.ancestors(ancestor)[:-1]\n",
    "\n",
    "nodes_to_update = [group for group in all_ancestors if group not in top_nodes]\n",
    "nodes_to_update.sort(key=lambda x:x.index)\n",
    "\n",
    "print 'Nodes to Update: {}'.format(len(nodes_to_update))\n",
    "print \"All Reactant Groups: {}\".format(len(all_reactant_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#for entry in ts_database.groups.entries:\n",
    "#    ts_database.groups.entries[entry].training_data = []\n",
    "\n",
    "#Attributes of each entry\n",
    "groupComments = {}; groupCounts = {}; groupUncertainties = {}; groupValues = {}\n",
    "for entry in all_entries:\n",
    "    groupComments[entry] = set()\n",
    "    groupCounts[entry] = []\n",
    "    groupUncertainties[entry] = []\n",
    "    groupValues[entry] = []\n",
    "\n",
    "#distance_keys = sorted(training_set[0][1].keys())\n",
    "distance_keys = ['d12', 'd13', 'd23']\n",
    "\n",
    "#all_updated = []\n",
    "A = []\n",
    "B = []\n",
    "for reaction, distance_data in training_set:\n",
    "    template = all_reactant_groups[reaction]\n",
    "    distances_list = [distance_data[key] for key in distance_keys]\n",
    "    #distance_data = numpy.array(distance_list)\n",
    "    relavent_combinations = []\n",
    "    for reactant_group in all_reactant_groups[reaction]:\n",
    "        relavent_combinations.append(all_ancestors[reactant_group])\n",
    "    assert len(relavent_combinations) == 2 #will throw if reaction does not have 2 reactants\n",
    "        \n",
    "    relavent_combinations = getAllCombinations(relavent_combinations)\n",
    "    #rel_comb is just all combinations of reactant1 and its ancestors with reactant2 and its ancestors\n",
    "    \n",
    "    for combination in relavent_combinations:\n",
    "        Arow = [1 if group in combination else 0 for group in nodes_to_update]\n",
    "        #Arow.append(1)\n",
    "        #Arow is a binary vector of len(groupList)+1 representing contributing groups to this reaction's distance data\n",
    "        A.append(Arow)\n",
    "        B.append(distances_list)\n",
    "        for group in combination:\n",
    "            if isinstance(group, str):\n",
    "                assert False\n",
    "                group = self.entries[group]\n",
    "\n",
    "            groupComments[group].add('{0!s}'.format(template))\n",
    "\n",
    "print \"Length of A: {}\".format(len(A))\n",
    "print\n",
    "            \n",
    "A = numpy.array(A)\n",
    "B = numpy.array(B)\n",
    "\n",
    "#######################################################################\n",
    "# What I think is going on:\n",
    "# Groups M and N are associated with a reaction that produces distances\n",
    "# Groups M and N must add together in some manner to get as close to this distance as well as in all other reactions of different combinations\n",
    "# Design matrix of size (All possible group combinations for all possible reactions) by (all groups + 1). Last row is needed for intercept\n",
    "    \n",
    "#distance_keys = sorted(training_set[0][1].distance.keys())\n",
    "#distance_keys = ['d12', 'd13', 'd23']\n",
    "\n",
    "x, residuals, rank, s = numpy.linalg.lstsq(A, B)\n",
    "#x, residual = nnls(A, B)\n",
    "for i, distance_key in enumerate(distance_keys):\n",
    "    # Determine error in each group\n",
    "    variance_sums = numpy.zeros(len(nodes_to_update)+1, numpy.float64)\n",
    "    stdev = numpy.zeros(len(nodes_to_update)+1, numpy.float64)\n",
    "    counts = numpy.zeros(len(nodes_to_update)+1, numpy.int)\n",
    "\n",
    "    #it seems convoluted but it creates a list of variances for all entries in groups entries\n",
    "    #the last item of the list is the sum of variances for the entire list which represents the entry\n",
    "\n",
    "    #for index in range(len(trainingSet)):\n",
    "    #for index, [reaction, distances] in enumerate(trainingSet):\n",
    "    for reaction, distances in training_set:\n",
    "        template = all_reactant_groups[reaction]\n",
    "        \n",
    "        distances_list = [distance_data[key] for key in distance_keys]\n",
    "        d = numpy.float64(distances_list[i])\n",
    "        dm = x[-1,i] + sum([x[nodes_to_update.index(group),i] for group in template if group in nodes_to_update])\n",
    "        \n",
    "        variance = (dm - d)**2\n",
    "        \n",
    "        for group in template:\n",
    "            for ancestor in all_ancestors[group]:\n",
    "                if ancestor not in top_nodes:\n",
    "                    ind = nodes_to_update.index(ancestor)\n",
    "                    variance_sums[ind] += variance\n",
    "                    counts[ind] += 1\n",
    "        variance_sums[-1] += variance\n",
    "        counts[-1] += 1\n",
    "\n",
    "    #import scipy.stats\n",
    "    ci = numpy.zeros(len(counts))\n",
    "    #for i in range(len(count)):\n",
    "    for j, count in enumerate(counts):\n",
    "        if count > 1:\n",
    "            stdev[j] = numpy.sqrt(variance_sums[j] / (count - 1))\n",
    "            ci[j] = scipy.stats.t.ppf(0.975, count - 1) * stdev[j]\n",
    "            #'probability density function'\n",
    "        else:\n",
    "            stdev[j] = None\n",
    "            ci[j] = None\n",
    "    \n",
    "    # Update dictionaries of fitted group values and uncertainties\n",
    "    for entry in all_entries:\n",
    "        if entry == top_nodes[0]:\n",
    "            groupValues[entry].append(x[-1, i])\n",
    "            groupUncertainties[entry].append(ci[-1])\n",
    "            groupCounts[entry].append(counts[-1])\n",
    "        elif entry.label in [group.label for group in nodes_to_update]:\n",
    "            #index = [group.label for group in groupList].index(entry.label)\n",
    "            index = nodes_to_update.index(entry)\n",
    "            groupValues[entry].append(x[index,i])\n",
    "            groupUncertainties[entry].append(ci[index])\n",
    "            groupCounts[entry].append(counts[index])\n",
    "        else:\n",
    "            groupValues[entry] = None\n",
    "            groupUncertainties[entry] = None\n",
    "            groupCounts[entry] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for entry in all_entries:\n",
    "    print entry.label\n",
    "    print groupValues[entry]\n",
    "    print groupUncertainties[entry]\n",
    "    print len(groupComments[entry])\n",
    "    break\n",
    "print\n",
    "for entry in all_entries:\n",
    "    if entry.index == 5:\n",
    "        print entry.label\n",
    "        print groupValues[entry]\n",
    "        print groupUncertainties[entry]\n",
    "        print len(groupComments[entry])\n",
    "        break\n",
    "\n",
    "neg = []\n",
    "all_neg = []\n",
    "impossible = []\n",
    "for entry in groupValues:\n",
    "    distances = groupValues[entry]\n",
    "    uncertainties = groupUncertainties[entry]\n",
    "    if distances is not None:\n",
    "        has_neg = False\n",
    "        has_all_neg = False\n",
    "        #Impossible ones have negative distances and uncertainties too small to create a range with positive values\n",
    "        is_impossible = False\n",
    "        \n",
    "        if distances[0] < 0 or distances[1] < 0 or distances[2] < 0:\n",
    "            has_neg = True\n",
    "        \n",
    "        if distances[0] < 0 and distances[1] < 0 and distances[2] < 0:\n",
    "            has_all_neg = True\n",
    "        \n",
    "        if distances[0] < 0 and distances[0] + uncertainties[0] < 0:\n",
    "            is_impossible = True\n",
    "        \n",
    "        if distances[1] < 0 and distances[1] + uncertainties[1] < 0:\n",
    "            is_impossible = True\n",
    "        \n",
    "        if distances[2] < 0 and distances[2] + uncertainties[2] < 0:\n",
    "            is_impossible = True\n",
    "        \n",
    "        if has_neg:\n",
    "            neg.append(entry)\n",
    "        if has_all_neg:\n",
    "            all_neg.append(entry)\n",
    "        if is_impossible:\n",
    "            impossible.append(entry)\n",
    "print\n",
    "print \"Atleast one negative: {}\".format(len(neg))\n",
    "print \"All negative: {}\".format(len(all_neg))\n",
    "print \"Negative and too small unvertainty: {}\".format(len(impossible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = []\n",
    "for i in range(5):\n",
    "    A_row = []\n",
    "    for j in range(5):\n",
    "        y = 0\n",
    "        if i == j:\n",
    "            y = 2\n",
    "        A_row.append(y)\n",
    "    A.append(A_row)\n",
    "    \n",
    "A = numpy.array(A)\n",
    "B = range(5,10)\n",
    "x, residuals = nnls(A,B)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = 2*numpy.random.rand(10,3)+1\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B = numpy.array\n",
    "B = numpy.zeros((10,3))\n",
    "B[:,0] = (A[:,1]**2+A[:,2]**2-A[:,0]**2)/(2*A[:,1])\n",
    "B[:,2] = (A[:,0]**2+A[:,1]**2-A[:,2]**2)/(2*A[:,1])\n",
    "B[:,1] = numpy.sqrt(A[:,2]**2 - B[:,0]**2)\n",
    "#B = 2*B\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TS_Database_Update(families, auto_save = False):\n",
    "    \"\"\"\n",
    "    Loads RMG Databse,\n",
    "    Creaes instance of TS_updater for each reaction family in families,\n",
    "    Return dictionary of family:family's instance of the updater\n",
    "    \"\"\"\n",
    "    \n",
    "    assert isinstance(families, list), \"Families must be a list. If singular family, still keep it in list\"\n",
    "    acceptable_families = os.listdir(os.path.join(os.path.expandvars(\"$RMGpy\"), \"..\", \"AutoTST\", \"database\"))\n",
    "    for family in families:\n",
    "        assert isinstance(family, str), \"Family names must be provided as strings\"\n",
    "        if family.upper() not in (family.upper() for family in acceptable_families):\n",
    "            logging.warning('\"{}\" is not a known Kinetics Family'.format(family))\n",
    "            families.remove(family)\n",
    "    \n",
    "    logging.info(\"Loading RMG Database...\")\n",
    "    rmg_database = RMGDatabase()\n",
    "    database_path = os.path.join(os.path.expandvars('$RMGpy'), \"..\",  'RMG-database', 'input')\n",
    "    \n",
    "    try:\n",
    "        rmg_database.load(database_path,\n",
    "                         #kineticsFamilies=['H_Abstraction'],\n",
    "                         kineticsFamilies=families,\n",
    "                         transportLibraries=[],\n",
    "                         reactionLibraries=[],\n",
    "                         seedMechanisms=[],\n",
    "                         thermoLibraries=['primaryThermoLibrary', 'thermo_DFT_CCSDTF12_BAC', 'CBS_QB3_1dHR' ],\n",
    "                         solvation=False,\n",
    "                         )\n",
    "    except:\n",
    "        logging.error(\"Failed to Load RMG Database at {}\".format(database_path))\n",
    "    \n",
    "    Databases = {family:TS_Updater(family, rmg_database) for family in families}\n",
    "    \n",
    "    if auto_save == True:\n",
    "        save_all_individual_databases(Databases)\n",
    "    \n",
    "    return Databases\n",
    "\n",
    "def save_all_individual_databases(Databases):\n",
    "    \"\"\"\n",
    "    To save all TS_updater instances by means of the dict supplied by TS_Database_Update()\n",
    "    \"\"\"\n",
    "    for family, database in Databases:\n",
    "        database.save_database()\n",
    "    return\n",
    "    \n",
    "################################################################################################\n",
    "\n",
    "class TS_Updater:\n",
    "    \"\"\"\n",
    "    Class for use in updating TS training databases\n",
    "    \n",
    "    Attributes:\n",
    "    self.family                 : Relavent Reaction Family\n",
    "    self.path                   : Path to family\n",
    "    self.database               : Source for TS geometries\n",
    "    self.training_set           : Lists of Reaction and corresponding TS Geometries\n",
    "    \n",
    "    self.top_nodes              : The two top nodes of the tree of related structures\n",
    "    self.all_entries            : All the nodes in the tree\n",
    "    \n",
    "    self.direct_groups          : Group that is directly matched with reactant structure\n",
    "    self.nodes_to_update        : Unique list of direct groups and their ancestors\n",
    "    self.group_ancestors        : Dict organized by {direct group: list of direct groups and its ancestors}\n",
    "    self.reaction_templates     : The two groups associated with a given reaction's reactants, organized by reaction\n",
    "    \n",
    "    self.groupComments          : Templates that are relavent to that entry\n",
    "    self.groupCounts            : Number of relavant combinations of groups that contribute to that entry\n",
    "    self.groupUncertainties     : Uncertainty in the optimized TS geometry for that node/entry\n",
    "    self.groupValues            : Optimized TS geometry for that node/entry\n",
    "\n",
    "    self.A                      : Binary Matrix (all combinations of those relavent groups for all reactions) by (relavant groups + 1)\n",
    "    self.b                      : Ax=b, x is found, b is (all combinations of relavent groups for all reactions) by (3 distances) \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, family, rmg_database, path = None):\n",
    "        \n",
    "        if path is not None:\n",
    "            self.path = path\n",
    "        else:\n",
    "            self.path = os.path.join(os.path.expandvars(\"$RMGpy\"), \"..\", \"AutoTST\", \"database\", family)\n",
    "            \n",
    "        self.family = family\n",
    "        \n",
    "        self.set_TS_training_data(rmg_database)\n",
    "        \n",
    "        self.update_indices()\n",
    "        self.set_group_info()\n",
    "        self.initialize_entry_attributes()\n",
    "        self.adjust_distances()\n",
    "        self.set_entry_data()\n",
    "\n",
    "    \n",
    "    def set_TS_training_data(self, rmg_database):\n",
    "        \"\"\"\n",
    "        Loads Database, sets it as class attribute, sets training_set from database\n",
    "        \"\"\"\n",
    "        from autotst.database import DistanceData, TransitionStateDepository, TSGroups, TransitionStates\n",
    "        ts_database = TransitionStates()\n",
    "        path = os.path.join(os.path.expandvars(\"$RMGpy\"), \"..\")\n",
    "        #path = self.path\n",
    "        global_context = { '__builtins__': None }\n",
    "        local_context={'DistanceData': DistanceData}\n",
    "        assert self.family in rmg_database.kinetics.families.keys(), \"{} not found in kinetics families. Could not Load\".format(family)\n",
    "        family = rmg_database.kinetics.families[self.family]\n",
    "        ts_database.family = family\n",
    "        ts_database.load(path, local_context, global_context)\n",
    "        self.database = ts_database\n",
    "        # Reaction must be a template reaction... found above\n",
    "        \n",
    "        logging.info(\"Getting Training Data for {}\".format(family))\n",
    "        training_data = [ (entry.item, entry.data.distances) for entry in list(ts_database.depository.entries.itervalues())]\n",
    "        self.training_set = training_data\n",
    "        logging.info(\"Total Distances Count: {}\".format(len(self.training_set)))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def update_indices(self):\n",
    "        \"\"\"\n",
    "        Updating entry indices based off of tree indices, tree indices are found by descending the tree\n",
    "        Without this, indices will be based off of previous database which may not be aligned by the current tree\n",
    "        \"\"\"\n",
    "        all_entries = []\n",
    "        self.top_nodes = self.database.groups.top\n",
    "        assert len(self.top_nodes) == 2, 'Only set to work for trees with two top nodes. It has: {}'.format(len(self.top_nodes))\n",
    "        \n",
    "        for top_node in self.top_nodes:\n",
    "            descendants = [top_node] + self.database.groups.descendants(top_node)\n",
    "            all_entries.extend(descendants)\n",
    "\n",
    "        for tree_index, entry in enumerate(all_entries):\n",
    "            #tree_indices[entry] = tree_index\n",
    "            self.database.groups.entries[entry.label].index = tree_index\n",
    "            entry.index = tree_index\n",
    "        \n",
    "        self.all_entries = all_entries\n",
    "        logging.info(\"Updating Indices based off of Tree...\")\n",
    "        logging.info(\"Tree size: {}\".format(len(all_entries)))\n",
    "        return\n",
    "\n",
    "\n",
    "    def set_group_info(self):\n",
    "        \"\"\"\n",
    "        Sets useful group info that is used by further class methods\n",
    "        \"\"\"\n",
    "        \n",
    "        #Direct groups are the lowest level node that matches the reactant structure\n",
    "        direct_groups = []\n",
    "        all_reactant_groups = {} #the two groups (template) of the reactants organized by reactions\n",
    "\n",
    "        for reaction, distance_data in self.training_set:\n",
    "            reactant_groups = [] #The groups that represent each reactant - also known as the template\n",
    "            \"\"\"    \n",
    "            for reactant in reaction.reactants:\n",
    "                reactant = reactant.molecule[0]\n",
    "\n",
    "                atoms = list(reactant.getLabeledAtoms().itervalues())\n",
    "                assert atoms is not None\n",
    "\n",
    "                for top_node in self.top_nodes:\n",
    "                    temp_group = self.database.groups.descendTree(reactant, atoms, root=top_node)\n",
    "                    if temp_group is not None:     #Temp_group will only be found using one of the two top_nodes\n",
    "                        reactant_group = temp_group\n",
    "                        break\n",
    "\n",
    "                assert reactant_group is not None\n",
    "\n",
    "                if isinstance(reactant_group, str):\n",
    "                    assert False, \"Versioning control problem: This should be a redundant check, but clearly is not in this case\"\n",
    "                    reactant_group = ts_database.groups.entries[reactant_group]\n",
    "                assert isinstance(reactant_group, Entry)\n",
    "            \"\"\"\n",
    "    \n",
    "            for top_node in self.top_nodes:\n",
    "\n",
    "                for reactant in reaction.reactants:\n",
    "                    if isinstance(reactant, rmgpy.species.Species):\n",
    "                        reactant = reactant.molecule[0]\n",
    "\n",
    "                    atoms = list(reactant.getLabeledAtoms().itervalues())\n",
    "                    assert atoms is not None\n",
    "\n",
    "                    #temp_group = self.database.groups.descendTree(reactant, atoms, root=top_node)\n",
    "                    temp_group = self.database.groups.descendTree(reactant, atoms, root=top_node)\n",
    "                    if temp_group is not None:     #Temp_group will only be found using one of the two top_nodes\n",
    "                        reactant_group = temp_group\n",
    "                        break\n",
    "\n",
    "\n",
    "                reactant_groups.append(reactant_group)        \n",
    "                direct_groups.append(reactant_group)\n",
    "\n",
    "            all_reactant_groups[reaction] = reactant_groups #storing the templates by reaction\n",
    "\n",
    "        direct_groups = list(set(direct_groups))\n",
    "        direct_groups.sort(key=lambda x:x.index)\n",
    "\n",
    "        all_ancestors = {} #Key is group, value is its itself and all its ancestors\n",
    "        for direct_group in direct_groups:\n",
    "            ancestors = [direct_group] + self.database.groups.ancestors(direct_group)\n",
    "            for ancestor in ancestors:\n",
    "                if ancestor in all_ancestors.keys():\n",
    "                    continue\n",
    "                else:\n",
    "                    all_ancestors[ancestor] = [ancestor] + self.database.groups.ancestors(ancestor)\n",
    "\n",
    "        # We need a list of unique nodes that are directly involved in a reaction or the ancestor of a group that is\n",
    "        nodes_to_update = [group for group in all_ancestors if group not in self.top_nodes]\n",
    "        nodes_to_update.sort(key=lambda x:x.index)\n",
    "\n",
    "        #Group info that is needed to simplify following methods\n",
    "        self.direct_groups = direct_groups\n",
    "        self.nodes_to_update = nodes_to_update\n",
    "        self.group_ancestors = all_ancestors\n",
    "        self.reaction_templates = all_reactant_groups\n",
    "        \n",
    "        logging.info('Nodes to Update: {}'.format(len(self.nodes_to_update)))\n",
    "        logging.info(\"Reaction Templates: {}\".format(len(self.reaction_templates)))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def initialize_entry_attributes(self):\n",
    "        \"\"\"\n",
    "        Attributes of each entry, initializing to size of all_entries\n",
    "        \"\"\"\n",
    "        self.groupComments = {}; self.groupCounts = {}; self.groupUncertainties = {}; self.groupValues = {}\n",
    "        for entry in self.all_entries:\n",
    "            self.groupComments[entry] = set()\n",
    "            self.groupCounts[entry] = []\n",
    "            self.groupUncertainties[entry] = []\n",
    "            self.groupValues[entry] = []\n",
    "        return\n",
    "    \n",
    "    def adjust_distances(self):\n",
    "        \"\"\"\n",
    "        Creating A and b of Ax=b\n",
    "        \"\"\"\n",
    "        def getAllCombinations(nodeLists):\n",
    "            \"\"\"\n",
    "            From base.py:\n",
    "            Generate a list of all possible combinations of items in the list of\n",
    "            lists `nodeLists`. Each combination takes one item from each list\n",
    "            contained within `nodeLists`. The order of items in the returned lists\n",
    "            reflects the order of lists in `nodeLists`. For example, if `nodeLists` was\n",
    "            [[A, B, C], [N], [X, Y]], the returned combinations would be\n",
    "            [[A, N, X], [A, N, Y], [B, N, X], [B, N, Y], [C, N, X], [C, N, Y]].\n",
    "            \"\"\"\n",
    "\n",
    "            items = [[]]\n",
    "            for nodeList in nodeLists:\n",
    "                items = [ item + [node] for node in nodeList for item in items ]\n",
    "\n",
    "            return items\n",
    "        ##############################################\n",
    "    \n",
    "        distance_keys = sorted(self.training_set[0][1].keys())\n",
    "        #distance_keys are ['d12', 'd13', 'd23']\n",
    "\n",
    "        A = []\n",
    "        b = []\n",
    "        for reaction, distance_data in self.training_set:\n",
    "            template = self.reaction_templates[reaction]\n",
    "            distances_list = [distance_data[key] for key in distance_keys]\n",
    "\n",
    "            relavent_combinations = []\n",
    "            for reactant_group in template:\n",
    "                relavent_combinations.append(self.group_ancestors[reactant_group])\n",
    "            assert len(relavent_combinations) == 2 #will throw if reaction does not have 2 reactants\n",
    "\n",
    "            relavent_combinations = getAllCombinations(relavent_combinations)\n",
    "            #rel_comb is just all combinations of reactant1 and its ancestors with reactant2 and its ancestors\n",
    "\n",
    "            for combination in relavent_combinations:\n",
    "                Arow = [1 if group in combination else 0 for group in self.nodes_to_update]\n",
    "                Arow.append(1) #For use in finding the family component\n",
    "                #Arow is a binary vector of len(groupList)+1 representing contributing groups to this reaction's distance data\n",
    "                A.append(Arow)\n",
    "                b.append(distances_list)\n",
    "                for group in combination:\n",
    "                    if isinstance(group, str):\n",
    "                        assert False, \"Discrepancy between versions of RMG_Database and this one\"\n",
    "\n",
    "                    self.groupComments[group].add('{0!s}'.format(template))\n",
    "\n",
    "        self.A = numpy.array(A)\n",
    "        self.b = numpy.array(b)\n",
    "        return\n",
    "    \n",
    "    def set_entry_data(self):\n",
    "        \"\"\"\n",
    "        Using A and b to find stats for relavent nodes of tree\n",
    "        \"\"\"\n",
    "        import scipy.stats\n",
    "        # Groups M and N are associated with a reaction that has a known ts geometry\n",
    "        # Groups M, N, and the family component must add together to get as close to that geometry as possible\n",
    "        # M and N are optimized based off of all reactionas they are involved with and the family component is optimized over all reactions of that family\n",
    "\n",
    "\n",
    "        distance_keys = sorted(self.training_set[0][1].keys())\n",
    "        #distance_keys are ['d12', 'd13', 'd23']\n",
    "\n",
    "        x, residuals, rank, s = numpy.linalg.lstsq(self.A, self.b)\n",
    "        for i, distance_key in enumerate(distance_keys):\n",
    "            # Determine error in each group\n",
    "            variance_sums = numpy.zeros(len(self.nodes_to_update)+1, numpy.float64)\n",
    "            stdev = numpy.zeros(len(self.nodes_to_update)+1, numpy.float64)\n",
    "            counts = numpy.zeros(len(self.nodes_to_update)+1, numpy.int)\n",
    "\n",
    "            for reaction, distances in self.training_set:\n",
    "                template = self.reaction_templates[reaction]\n",
    "\n",
    "                distances_list = [distances[key] for key in distance_keys]\n",
    "                d = numpy.float64(distances_list[i])\n",
    "                #dm found by manually summing residuals\n",
    "                dm = x[-1,i] + sum([x[self.nodes_to_update.index(group),i] for group in template])\n",
    "\n",
    "\n",
    "                variance = (dm - d)**2\n",
    "\n",
    "                for group in template:\n",
    "                    for ancestor in self.group_ancestors[group]:\n",
    "                        if ancestor not in self.top_nodes:\n",
    "                            ind = self.nodes_to_update.index(ancestor)\n",
    "                            variance_sums[ind] += variance\n",
    "                            counts[ind] += 1\n",
    "                variance_sums[-1] += variance\n",
    "                counts[-1] += 1\n",
    "                \n",
    "            ci = numpy.zeros(len(counts))\n",
    "\n",
    "            for j, count in enumerate(counts):\n",
    "                if count > 2:\n",
    "                    stdev[j] = numpy.sqrt(variance_sums[j] / (count - 1))\n",
    "                    ci[j] = scipy.stats.t.ppf(0.975, count - 1) * stdev[j]\n",
    "                else:\n",
    "                    stdev[j] = None\n",
    "                    ci[j] = None\n",
    "\n",
    "            # Update dictionaries of fitted group values and uncertainties\n",
    "            for entry in self.all_entries:\n",
    "                if entry == self.top_nodes[0]:\n",
    "                    self.groupValues[entry].append(x[-1, i])\n",
    "                    self.groupUncertainties[entry].append(ci[-1])\n",
    "                    self.groupCounts[entry].append(counts[-1])\n",
    "                elif entry.label in [group.label for group in self.nodes_to_update]:\n",
    "                    index = self.nodes_to_update.index(entry)\n",
    "                    \n",
    "                    self.groupValues[entry].append(x[index,i])\n",
    "                    self.groupUncertainties[entry].append(ci[index])\n",
    "                    self.groupCounts[entry].append(counts[index])\n",
    "                else:\n",
    "                    self.groupValues[entry] = None\n",
    "                    self.groupUncertainties[entry] = None\n",
    "                    self.groupCounts[entry] = None\n",
    "            \n",
    "            for entry in self.all_entries:\n",
    "                if self.groupValues[entry] is not None:\n",
    "                    if not any(numpy.isnan(numpy.array(self.groupUncertainties[entry]))):\n",
    "                        # should be entry.data.* (e.g. entry.data.uncertainties)\n",
    "                        uncertainties = numpy.array(self.groupUncertainties[entry])\n",
    "                        uncertaintyType = '+|-'\n",
    "                    else:\n",
    "                        uncertainties = {}\n",
    "                    # should be entry.*\n",
    "                    shortDesc = \"Fitted to {0} distances.\\n\".format(self.groupCounts[entry][0])\n",
    "                    longDesc = \"\\n\".join(self.groupComments[entry])\n",
    "                    distances_dict = {key:distance for key, distance in zip(distance_keys, self.groupValues[entry])}\n",
    "                    uncertainties_dict = {key:distance for key, distance in zip(distance_keys, uncertainties)}\n",
    "                    \n",
    "                    entry.data = DistanceData(distances=distances_dict, uncertainties=uncertainties_dict)\n",
    "                    entry.shortDesc = shortDesc\n",
    "                    entry.longDesc = longDesc\n",
    "                else:\n",
    "                    entry.data = DistanceData()\n",
    "                    entry.longDesc = ''\n",
    "        logging.info(\"Finished Updating Entries for {}\\n\".format(self.family))\n",
    "        return\n",
    "        \n",
    "    def save_database(self, path = None):\n",
    "        if path is None and self.path is None:\n",
    "            logging.error(\"Need path to save output\")\n",
    "        elif path is None:\n",
    "            path = os.join(self.path, 'TS_groups.py')\n",
    "\n",
    "        self.database.saveTransitionStateGroups(path)\n",
    "        logging.info('Saved {} Database to: {}'.format(self.family, path))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
